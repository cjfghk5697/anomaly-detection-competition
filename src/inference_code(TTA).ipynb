{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_CNMKV8VdMV"
      },
      "source": [
        "#07-17 \n",
        "이상하게 갑자기 앙상블이 이상해짐. 그리고 테스트로 Transforms를 적용한 상태로 하는중\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W-ubNrT9Ctxy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_BzNc1s_CHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc332d5c-b480-4e35-ec02-8faa61528b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRj_m3HDlUxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84567197-4a64-4bd9-bff9-301ffb29f9a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/input\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/input/\"\n",
        "!unzip -q \"/content/drive/MyDrive/input/test.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDsQlo2TAVaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b46426-d990-4a90-a536-455010ab9750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.5-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.0+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.6.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ttach\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Installing collected packages: ttach\n",
            "Successfully installed ttach-0.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip3 install timm\n",
        "!pip install ttach\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlVmS_SvlTkn"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import ttach as tta\n",
        "\n",
        "import os\n",
        "import random\n",
        "import timm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import time\n",
        "from typing import Tuple, Sequence, Callable\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from autoaugment import ImageNetPolicy, CIFAR10Policy, SVHNPolicy, SubPolicy\n",
        "from torchvision.models import efficientnet_v2_s\n",
        "\n",
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxC2X9eXlSIQ"
      },
      "outputs": [],
      "source": [
        "test_png = sorted(glob('/content/drive/MyDrive/input/test/*.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxYBColRAZe2"
      },
      "outputs": [],
      "source": [
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1]\n",
        "    img = cv2.resize(img, (512, 512))\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWGDGwa7lPgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f20f953-bccf-4040-f0fb-ab0453ba8be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2154/2154 [01:36<00:00, 22.25it/s]\n"
          ]
        }
      ],
      "source": [
        "test_imgs = [img_load(n) for n in tqdm(test_png)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn0Lq8w4-DHN"
      },
      "outputs": [],
      "source": [
        "transforms_test = transforms.Compose([\n",
        "    ImageNetPolicy(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4DNAqNkBnkR"
      },
      "outputs": [],
      "source": [
        "train_y = pd.read_csv('/content/drive/MyDrive/input/train_df.csv')\n",
        "\n",
        "train_labels = train_y[\"label\"]\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpQdWTyW-B4V"
      },
      "outputs": [],
      "source": [
        "class Custom_dataset(Dataset):\n",
        "    def __init__(self, \n",
        "                 img_paths, \n",
        "                 labels, \n",
        "                 mode='train',\n",
        "                 transforms= Sequence[Callable]\n",
        "            ) -> None:\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode=='train':\n",
        "            augmentation = random.randint(0,2)\n",
        "            if augmentation==1:\n",
        "                img = img[::-1].copy()\n",
        "            elif augmentation==2:\n",
        "                img = img[:,::-1].copy()\n",
        "        if self.mode=='test':\n",
        "            pass\n",
        "        img = Image.fromarray(img) # NumPy array to PIL image\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)        \n",
        "        label = self.labels[idx]\n",
        " #       return {'image': img, 'label': label} #TTA사용\n",
        "        return img, label # 단일 버전\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        #self.model = timm.create_model('efficientnet_b3', pretrained=True)\n",
        "        self.model = efficientnet_v2_s(pretrained=True)\n",
        "        self.dropout=nn.Dropout(p=0.2)\n",
        "        self.SiLU=nn.SiLU(inplace=False)\n",
        "        self.classifier = nn.Linear(1000, 88)\n",
        "        nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.SiLU(x) \n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Network().to(device)\n",
        "model.to(device)# gpu에 모델 할당"
      ],
      "metadata": {
        "id": "FAYomo-4FrH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = []"
      ],
      "metadata": {
        "id": "_JopzWajF33y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/input/model/eff v2 sm Adamw 2e-4 2e-2.pth'), strict=False)\n",
        "#best_models.append(copy.deepcopy(model)) #64\n",
        "model.load_state_dict(torch.load('eff v2 imageNet radam.pth'), strict=False) #56\n",
        "best_models.append(copy.deepcopy(model)) \n",
        "#0.9860520407418223_0.2941494585525086\n",
        "#0.9502637631425235_0.3421912490297702 #56"
      ],
      "metadata": {
        "id": "7TNRiBLXFmNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"model.load_state_dict(torch.load('/content/drive/MyDrive/input/model/eff3 adamw 2e-4, 2e-2, gradscaler.pth'), strict=False)\n",
        "best_models.append(copy.deepcopy(model)) #61%\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/input/model/cosine,eff3,66.pth'), strict=False)\n",
        "best_models.append(copy.deepcopy(model)) #63\"\"\""
      ],
      "metadata": {
        "id": "PKOZVyknFnhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMXgCkKT_I0D"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Network().to(device)\n",
        "model.to(device)# gpu에 모델 할당\n",
        "\n",
        "import copy\n",
        "best_models = []\n",
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/input/model/Focal loss,eff3,47.pth'), strict=False)\n",
        "#best_models.append(copy.deepcopy(model)) # 48%\n",
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/input/model/eff3 2e-2 adamw.pth'), strict=False)\n",
        "#best_models.append(copy.deepcopy(model)) #9%\n",
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/input/model/eff3 adamw 2e-4, 2e-2, gradscaler.pth'), strict=False)\n",
        "#best_models.append(copy.deepcopy(model)) #61%\n",
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/input/model/cosine,eff3,66.pth'), strict=False)\n",
        "#best_models.append(copy.deepcopy(model)) #63\n",
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/input/model/eff v2 sm Adamw 2e-4 2e-2.pth'), strict=False)\n",
        "#best_models.append(copy.deepcopy(model)) #64\n",
        "\n",
        "apply_tta_model=[]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "apply_tta_model=[]"
      ],
      "metadata": {
        "id": "Basm4Eflnc9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLBliXglmru5"
      },
      "outputs": [],
      "source": [
        "tta_transforms = tta.Compose(\n",
        "    [\n",
        "        tta.Rotate90(angles=[0, 90, 180, 270]),\n",
        "        tta.Multiply([0.9, 1]),\n",
        "    ]\n",
        ")\n",
        "for model in best_models:\n",
        "   apply_tta_model.append(copy.deepcopy(tta.ClassificationTTAWrapper(model, tta_transforms)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 6\n",
        "\n",
        "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test',transforms=transforms_test)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False,num_workers=6, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "O5QC4l-Cmyla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVfI3bMbmsoG"
      },
      "outputs": [],
      "source": [
        "\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad  ():\n",
        "    for batch in (test_loader):\n",
        "        pred=0\n",
        "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            for model in best_models:\n",
        "              model.eval()\n",
        "              pred += model(x)\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEtJH3_QlgVo"
      },
      "outputs": [],
      "source": [
        "label_decoder = {val:key for key, val in label_unique.items()}\n",
        "\n",
        "f_result = [label_decoder[result] for result in f_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYYMDVz9lhxH"
      },
      "outputs": [],
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/input/sample_submission.csv')\n",
        "\n",
        "submission[\"label\"] = f_result\n",
        "\n",
        "submission.to_csv(\"/content/drive/MyDrive/input/baseline1.csv\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5QVMNLEWOpl"
      },
      "source": [
        "https://dacon.io/competitions/official/235894/codeshare/4946?page=1&dtype=recent\n",
        "\n",
        "[파일 정리](https://dacon.io/forum/402762?page=1&dtype=recent&ptype&fType)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "inference code(TTA).ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}