{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cjfghk5697/anomaly-detection-competition/blob/main/Add_lr%20scheduler%2Camp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IbKCV5mvcNt"
      },
      "source": [
        "# 기록\n",
        "\n",
        "## 07-09\n",
        "\n",
        "# lr scheduler 추가\n",
        "```python\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001, last_epoch=-1)\n",
        "```\n",
        "# amp 구현\n",
        "[pytorch](https://tutorials.pytorch.kr/recipes/recipes/amp_recipe.html)\n",
        "```python\n",
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp) \n",
        "```\n",
        "amp란 scaler 두개 gradscaler과 autocast를 합쳐 사용하는 건데 이 두개를 같이 쓰면 성능은 유지되면서 gpu 메모리 소모는 줄고 연산 속도가 증가한다. 거의 2~3배 정도 빨라진다.\n"
      ],
      "id": "9IbKCV5mvcNt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ-sBHD67ara"
      },
      "source": [
        "https://dacon.io/competitions/official/235894/overview/description"
      ],
      "id": "CZ-sBHD67ara"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzCathkdclQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cecdcbf4-eb80-49c6-d50a-eac49e0cd517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "PzCathkdclQi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT1TIhwClLco",
        "outputId": "e84b3f3d-a255-4d4c-c58c-40added6c0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/input\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/input/\"\n",
        "!unzip -q \"/content/drive/MyDrive/input/train.zip\" "
      ],
      "id": "XT1TIhwClLco"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFbYUT85c21S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b21adac-7808-4c45-e72c-2ed20b0f6443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip3 install timm"
      ],
      "id": "oFbYUT85c21S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAYn-e555h3X"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "import timm\n",
        "import random\n",
        "from typing import Tuple, Sequence, Callable\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import time\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "device = torch.device('cuda')"
      ],
      "id": "QAYn-e555h3X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hqIke8a5h3Y"
      },
      "outputs": [],
      "source": [
        "train_png = sorted(glob('./train/*.png'))"
      ],
      "id": "4hqIke8a5h3Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqVmNfwZ5h3Z"
      },
      "outputs": [],
      "source": [
        "train_y = pd.read_csv('./train_df.csv')\n",
        "\n",
        "train_labels = train_y[\"label\"]\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]"
      ],
      "id": "QqVmNfwZ5h3Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo8oWVcz5h3Z"
      },
      "outputs": [],
      "source": [
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1]\n",
        "    img = cv2.resize(img, (512, 512))\n",
        "    return img"
      ],
      "id": "qo8oWVcz5h3Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErXkcD7d5h3a",
        "outputId": "70003a14-52b0-4124-f260-83254644cdf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [02:16<00:00, 31.24it/s]\n"
          ]
        }
      ],
      "source": [
        "train_imgs = [img_load(m) for m in tqdm(train_png)]"
      ],
      "id": "ErXkcD7d5h3a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQfAK_29vky9"
      },
      "outputs": [],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n"
      ],
      "id": "aQfAK_29vky9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVB5_Crz5h3a"
      },
      "outputs": [],
      "source": [
        "class Custom_dataset(Dataset):\n",
        "    def __init__(self, \n",
        "                 img_paths, \n",
        "                 labels, \n",
        "                 mode='train',\n",
        "                 transforms= Sequence[Callable]\n",
        "            ) -> None:\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode=='train':\n",
        "            augmentation = random.randint(0,2)\n",
        "            if augmentation==1:\n",
        "                img = img[::-1].copy()\n",
        "            elif augmentation==2:\n",
        "                img = img[:,::-1].copy()\n",
        "        if self.mode=='test':\n",
        "            pass\n",
        "        img = Image.fromarray(img) # NumPy array to PIL image\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)        \n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "    \n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.model = timm.create_model('efficientnet_b3', pretrained=True)\n",
        "        self.dropout=nn.Dropout(p=0.2)\n",
        "        self.SiLU=nn.SiLU(inplace=False)\n",
        "        self.classifier = nn.Linear(1000, 88)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.SiLU(x) \n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ],
      "id": "GVB5_Crz5h3a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbhpWtL45h3b"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 30\n",
        "\n",
        "# Train\n",
        "trainset  = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train', transforms=transforms_train)\n",
        "lengths = [int(len(trainset)*0.8), int(len(trainset)*0.2)]\n"
      ],
      "id": "cbhpWtL45h3b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdORtwaH4dpb"
      },
      "outputs": [],
      "source": [
        "lengths=[lengths[0],lengths[1]+1]"
      ],
      "id": "sdORtwaH4dpb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzqumLFE4ATy"
      },
      "outputs": [],
      "source": [
        "train_dataset, valid_dataset = torch.utils.data.random_split(trainset, lengths)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_dataset, shuffle=True, batch_size=batch_size)"
      ],
      "id": "jzqumLFE4ATy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI-MFTELRNly"
      },
      "outputs": [],
      "source": [
        "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    if use_cuda:\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "id": "pI-MFTELRNly"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvqyW4n65h3b"
      },
      "source": [
        "### 모델 학습"
      ],
      "id": "hvqyW4n65h3b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QplKmNaD5h3b",
        "outputId": "bd290014-7d06-4f99-abf2-2f3df9a5acb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b3_ra2-cf984f9c.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_ra2-cf984f9c.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1/30    time : 127s/3674s\n",
            "TRAIN    loss : 1.96982    f1 : 0.09644\n",
            "valid    loss : 1.02031    f1 : 0.72353\n",
            "epoch : 2/30    time : 125s/3512s\n",
            "TRAIN    loss : 1.43325    f1 : 0.14429\n",
            "valid    loss : 0.70299    f1 : 0.71989\n",
            "epoch : 3/30    time : 125s/3371s\n",
            "TRAIN    loss : 1.33693    f1 : 0.15739\n",
            "valid    loss : 0.58033    f1 : 0.62210\n",
            "epoch : 4/30    time : 125s/3251s\n",
            "TRAIN    loss : 1.14045    f1 : 0.18390\n",
            "valid    loss : 0.82141    f1 : 0.75000\n",
            "epoch : 5/30    time : 125s/3130s\n",
            "TRAIN    loss : 1.11595    f1 : 0.20757\n",
            "valid    loss : 0.26041    f1 : 0.76667\n",
            "epoch : 6/30    time : 125s/2997s\n",
            "TRAIN    loss : 1.06353    f1 : 0.27052\n",
            "valid    loss : 0.33891    f1 : 0.82222\n",
            "epoch : 7/30    time : 125s/2878s\n",
            "TRAIN    loss : 1.00609    f1 : 0.28139\n",
            "valid    loss : 0.15439    f1 : 1.00000\n",
            "epoch : 8/30    time : 125s/2755s\n",
            "TRAIN    loss : 0.95493    f1 : 0.28537\n",
            "valid    loss : 0.36335    f1 : 0.71944\n",
            "epoch : 9/30    time : 125s/2626s\n",
            "TRAIN    loss : 0.98947    f1 : 0.27056\n",
            "valid    loss : 0.10190    f1 : 0.87500\n",
            "epoch : 10/30    time : 125s/2507s\n",
            "TRAIN    loss : 0.94018    f1 : 0.30162\n",
            "valid    loss : 0.33476    f1 : 0.87368\n",
            "epoch : 11/30    time : 125s/2384s\n",
            "TRAIN    loss : 0.94920    f1 : 0.33365\n",
            "valid    loss : 0.45858    f1 : 0.64444\n",
            "epoch : 12/30    time : 125s/2251s\n",
            "TRAIN    loss : 0.85627    f1 : 0.31646\n",
            "valid    loss : 0.04118    f1 : 1.00000\n",
            "epoch : 13/30    time : 125s/2127s\n",
            "TRAIN    loss : 0.82850    f1 : 0.38198\n",
            "valid    loss : 0.02387    f1 : 1.00000\n",
            "epoch : 14/30    time : 125s/2007s\n",
            "TRAIN    loss : 0.85959    f1 : 0.37196\n",
            "valid    loss : 0.23078    f1 : 0.83333\n",
            "epoch : 15/30    time : 125s/1873s\n",
            "TRAIN    loss : 0.82172    f1 : 0.37106\n",
            "valid    loss : 0.06574    f1 : 1.00000\n",
            "epoch : 16/30    time : 125s/1752s\n",
            "TRAIN    loss : 0.81988    f1 : 0.35938\n",
            "valid    loss : 0.04565    f1 : 1.00000\n",
            "epoch : 17/30    time : 125s/1629s\n",
            "TRAIN    loss : 0.79523    f1 : 0.39846\n",
            "valid    loss : 0.02383    f1 : 1.00000\n",
            "epoch : 18/30    time : 125s/1499s\n",
            "TRAIN    loss : 0.76399    f1 : 0.37584\n",
            "valid    loss : 0.02991    f1 : 1.00000\n",
            "epoch : 19/30    time : 125s/1379s\n",
            "TRAIN    loss : 0.78883    f1 : 0.37480\n",
            "valid    loss : 0.02054    f1 : 1.00000\n",
            "epoch : 20/30    time : 125s/1253s\n",
            "TRAIN    loss : 0.75216    f1 : 0.45085\n",
            "valid    loss : 0.09488    f1 : 0.85185\n",
            "epoch : 21/30    time : 125s/1129s\n",
            "TRAIN    loss : 0.74578    f1 : 0.44249\n",
            "valid    loss : 0.04191    f1 : 1.00000\n",
            "epoch : 22/30    time : 125s/1002s\n",
            "TRAIN    loss : 0.79463    f1 : 0.44884\n",
            "valid    loss : 0.02106    f1 : 1.00000\n",
            "epoch : 23/30    time : 125s/877s\n",
            "TRAIN    loss : 0.78968    f1 : 0.39747\n",
            "valid    loss : 0.11942    f1 : 0.82222\n",
            "epoch : 24/30    time : 125s/749s\n",
            "TRAIN    loss : 0.75854    f1 : 0.39032\n",
            "valid    loss : 0.00946    f1 : 1.00000\n",
            "epoch : 25/30    time : 125s/626s\n",
            "TRAIN    loss : 0.75872    f1 : 0.47756\n",
            "valid    loss : 0.11254    f1 : 0.90000\n",
            "epoch : 26/30    time : 125s/501s\n",
            "TRAIN    loss : 0.71284    f1 : 0.45580\n",
            "valid    loss : 0.05729    f1 : 1.00000\n",
            "epoch : 27/30    time : 125s/375s\n",
            "TRAIN    loss : 0.69121    f1 : 0.43086\n",
            "valid    loss : 0.03022    f1 : 1.00000\n",
            "epoch : 28/30    time : 125s/250s\n",
            "TRAIN    loss : 0.70897    f1 : 0.48444\n",
            "valid    loss : 0.01586    f1 : 1.00000\n",
            "epoch : 29/30    time : 125s/125s\n",
            "TRAIN    loss : 0.72385    f1 : 0.45718\n",
            "valid    loss : 0.01115    f1 : 1.00000\n",
            "epoch : 30/30    time : 125s/0s\n",
            "TRAIN    loss : 0.73999    f1 : 0.46330\n",
            "valid    loss : 0.03086    f1 : 1.00000\n"
          ]
        }
      ],
      "source": [
        "def score_function(real, pred):\n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score\n",
        "\n",
        "model = Network().to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp) \n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001, last_epoch=-1)\n",
        "\n",
        "\n",
        "valid_loss_list=[]\n",
        "train_loss_list=[]\n",
        "\n",
        "best=0\n",
        "for epoch in range(epochs):\n",
        "    start=time.time()\n",
        "    train_loss = 0\n",
        "    train_pred=[]\n",
        "    train_y=[]\n",
        "\n",
        "    valid_loss = 0\n",
        "    valid_pred=[]\n",
        "    valid_y=[]\n",
        "\n",
        "    model.train()\n",
        "    for batch in (train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
        "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "\n",
        "        x, targets_a, targets_b, lam = mixup_data(x, y)\n",
        "        x, targets_a, targets_b = map(Variable, (x, targets_a, targets_b))\n",
        "\n",
        "        #outputs = model(x)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        loss = mixup_criterion(criterion, pred, targets_a, targets_b, lam)\n",
        "\n",
        "\n",
        "        #loss = criterion(pred, y)\n",
        "\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        train_loss += loss.item()/len(train_loader)\n",
        "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "        train_y += y.detach().cpu().numpy().tolist()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in (valid_loader):\n",
        "          images = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
        "          targets = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "\n",
        "\n",
        "\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, targets)\n",
        "\n",
        "          valid_loss += loss.item()/len(valid_loader)\n",
        "          valid_pred += outputs.argmax(1).detach().cpu().numpy().tolist()\n",
        "          valid_y += targets.detach().cpu().numpy().tolist()\n",
        "    \n",
        "    train_f1 = score_function(train_y, train_pred)\n",
        "    valid_f1 = score_function(valid_y, valid_pred)\n",
        "\n",
        "    TIME = time.time() - start\n",
        "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
        "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
        "    print(f'valid    loss : {valid_loss:.5f}    f1 : {valid_f1:.5f}')\n",
        "    lr_scheduler.step()\n",
        "    torch.save(model.state_dict(), f'{train_loss}_{train_f1}.pth')"
      ],
      "id": "QplKmNaD5h3b"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Add valid, transforms.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}