{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cjfghk5697/anomaly-detection-competition/blob/main/Add_xavier%2C%20autoaugmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IbKCV5mvcNt"
      },
      "source": [
        "# 기록\n",
        "\n",
        "## 07-10\n",
        "결론: 여기서 적용한 transform 그대로 test에 적용하면 정확도가 떨어진다. 하지만 어떤 transform도 적용하지 않는다면 정확도가 1.5%정도 높아진다.\n",
        "\n",
        "# auto augment 추가\n",
        "```python\n",
        "!git clone https://github.com/DeepVoltaire/AutoAugment.git\n",
        "!cp /content/AutoAugment/autoaugment.py /content\n",
        "\n",
        "from autoaugment import ImageNetPolicy, CIFAR10Policy, SVHNPolicy, SubPolicy\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    ImageNetPolicy(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "```\n",
        "# 사비에르 초깃값 추가(xavier)\n",
        "```python\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.model = timm.create_model('efficientnet_b3', pretrained=True)\n",
        "        self.dropout=nn.Dropout(p=0.2)\n",
        "        self.SiLU=nn.SiLU(inplace=False)\n",
        "        self.classifier = nn.Linear(1000, 88)\n",
        "        nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.SiLU(x) \n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "```\n"
      ],
      "id": "9IbKCV5mvcNt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ-sBHD67ara"
      },
      "source": [
        "https://dacon.io/competitions/official/235894/overview/description"
      ],
      "id": "CZ-sBHD67ara"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzCathkdclQi",
        "outputId": "f5c3811b-11bb-4e9d-ef81-2f531292f19e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "PzCathkdclQi"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT1TIhwClLco",
        "outputId": "437b6200-6a9d-46fb-c5d0-ab366d3aecc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/input\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/input/\"\n",
        "!unzip -q \"/content/drive/MyDrive/input/train.zip\" "
      ],
      "id": "XT1TIhwClLco"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3OokVlgKZj4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91e57fb8-c095-4788-9595-5437a9b02e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AutoAugment' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# autoaugment 사용\n",
        "!git clone https://github.com/DeepVoltaire/AutoAugment.git\n",
        "!cp /content/drive/MyDrive/input/AutoAugment/autoaugment.py /content/drive/MyDrive/input\n",
        "!cp /content/drive/MyDrive/input/AutoAugment/ops.py /content/drive/MyDrive/input"
      ],
      "id": "3OokVlgKZj4-"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFbYUT85c21S",
        "outputId": "e586deda-1a5d-4dd7-a874-5c65a5f6a4cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip3 install timm"
      ],
      "id": "oFbYUT85c21S"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QAYn-e555h3X"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "import timm\n",
        "import random\n",
        "from typing import Tuple, Sequence, Callable\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import time\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from torch.autograd import Variable\n",
        "from autoaugment import ImageNetPolicy, CIFAR10Policy, SVHNPolicy, SubPolicy\n",
        "\n",
        "\n",
        "device = torch.device('cuda')"
      ],
      "id": "QAYn-e555h3X"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4hqIke8a5h3Y"
      },
      "outputs": [],
      "source": [
        "train_png = sorted(glob('./train/*.png'))"
      ],
      "id": "4hqIke8a5h3Y"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QqVmNfwZ5h3Z"
      },
      "outputs": [],
      "source": [
        "train_y = pd.read_csv('./train_df.csv')\n",
        "\n",
        "train_labels = train_y[\"label\"]\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]"
      ],
      "id": "QqVmNfwZ5h3Z"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qo8oWVcz5h3Z"
      },
      "outputs": [],
      "source": [
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1]\n",
        "    img = cv2.resize(img, (512, 512))\n",
        "    return img"
      ],
      "id": "qo8oWVcz5h3Z"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErXkcD7d5h3a",
        "outputId": "c6dfa62b-b473-46df-88a3-d9a399eed4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [02:35<00:00, 27.56it/s]\n"
          ]
        }
      ],
      "source": [
        "train_imgs = [img_load(m) for m in tqdm(train_png)]"
      ],
      "id": "ErXkcD7d5h3a"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "aQfAK_29vky9"
      },
      "outputs": [],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    ImageNetPolicy(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n"
      ],
      "id": "aQfAK_29vky9"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GVB5_Crz5h3a"
      },
      "outputs": [],
      "source": [
        "class Custom_dataset(Dataset):\n",
        "    def __init__(self, \n",
        "                 img_paths, \n",
        "                 labels, \n",
        "                 mode='train',\n",
        "                 transforms= Sequence[Callable]\n",
        "            ) -> None:\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode=='train':\n",
        "            augmentation = random.randint(0,2)\n",
        "            if augmentation==1:\n",
        "                img = img[::-1].copy()\n",
        "            elif augmentation==2:\n",
        "                img = img[:,::-1].copy()\n",
        "        if self.mode=='test':\n",
        "            pass\n",
        "        img = Image.fromarray(img) # NumPy array to PIL image\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)        \n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "    \n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.model = timm.create_model('efficientnet_b3', pretrained=True)\n",
        "        self.dropout=nn.Dropout(p=0.2)\n",
        "        self.SiLU=nn.SiLU(inplace=False)\n",
        "        self.classifier = nn.Linear(1000, 88)\n",
        "        nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.SiLU(x) \n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ],
      "id": "GVB5_Crz5h3a"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cbhpWtL45h3b"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 50\n",
        "\n",
        "# Train\n",
        "trainset  = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train', transforms=transforms_train)\n",
        "lengths = [int(len(trainset)*0.8), int(len(trainset)*0.2)]\n"
      ],
      "id": "cbhpWtL45h3b"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sdORtwaH4dpb"
      },
      "outputs": [],
      "source": [
        "lengths=[lengths[0],lengths[1]+1]"
      ],
      "id": "sdORtwaH4dpb"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jzqumLFE4ATy"
      },
      "outputs": [],
      "source": [
        "train_dataset, valid_dataset = torch.utils.data.random_split(trainset, lengths)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_dataset, shuffle=True, batch_size=batch_size)"
      ],
      "id": "jzqumLFE4ATy"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "pI-MFTELRNly"
      },
      "outputs": [],
      "source": [
        "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    if use_cuda:\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "id": "pI-MFTELRNly"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvqyW4n65h3b"
      },
      "source": [
        "### 모델 학습"
      ],
      "id": "hvqyW4n65h3b"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QplKmNaD5h3b",
        "outputId": "ad16583e-c6f0-4f15-9909-b999612e3c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b3_ra2-cf984f9c.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_ra2-cf984f9c.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1/50    time : 146s/7176s\n",
            "TRAIN    loss : 2.13073    f1 : 0.08712\n",
            "valid    loss : 0.92865    f1 : 0.56825\n",
            "epoch : 2/50    time : 145s/6944s\n",
            "TRAIN    loss : 1.58802    f1 : 0.12260\n",
            "valid    loss : 1.09543    f1 : 0.64630\n",
            "epoch : 3/50    time : 144s/6785s\n",
            "TRAIN    loss : 1.42663    f1 : 0.12408\n",
            "valid    loss : 0.47046    f1 : 0.68889\n",
            "epoch : 4/50    time : 145s/6659s\n",
            "TRAIN    loss : 1.37362    f1 : 0.15605\n",
            "valid    loss : 0.51606    f1 : 0.68421\n",
            "epoch : 5/50    time : 144s/6494s\n",
            "TRAIN    loss : 1.27411    f1 : 0.16124\n",
            "valid    loss : 0.44835    f1 : 0.79259\n",
            "epoch : 6/50    time : 145s/6386s\n",
            "TRAIN    loss : 1.27125    f1 : 0.20116\n",
            "valid    loss : 0.79291    f1 : 0.62857\n",
            "epoch : 7/50    time : 145s/6224s\n",
            "TRAIN    loss : 1.19173    f1 : 0.21249\n",
            "valid    loss : 0.62076    f1 : 0.65614\n",
            "epoch : 8/50    time : 145s/6074s\n",
            "TRAIN    loss : 1.13477    f1 : 0.23935\n",
            "valid    loss : 0.32429    f1 : 0.86667\n",
            "epoch : 9/50    time : 145s/5929s\n",
            "TRAIN    loss : 1.16468    f1 : 0.25433\n",
            "valid    loss : 0.40414    f1 : 0.73056\n",
            "epoch : 10/50    time : 145s/5796s\n",
            "TRAIN    loss : 1.10483    f1 : 0.26976\n",
            "valid    loss : 0.22484    f1 : 0.88889\n",
            "epoch : 11/50    time : 144s/5628s\n",
            "TRAIN    loss : 1.12646    f1 : 0.26180\n",
            "valid    loss : 0.35820    f1 : 0.78932\n",
            "epoch : 12/50    time : 145s/5497s\n",
            "TRAIN    loss : 1.11536    f1 : 0.25713\n",
            "valid    loss : 0.09821    f1 : 1.00000\n",
            "epoch : 13/50    time : 144s/5334s\n",
            "TRAIN    loss : 1.04617    f1 : 0.29749\n",
            "valid    loss : 0.18904    f1 : 0.91111\n",
            "epoch : 14/50    time : 145s/5208s\n",
            "TRAIN    loss : 1.02037    f1 : 0.29099\n",
            "valid    loss : 0.38232    f1 : 0.75556\n",
            "epoch : 15/50    time : 144s/5038s\n",
            "TRAIN    loss : 1.01613    f1 : 0.28441\n",
            "valid    loss : 0.27776    f1 : 0.92593\n",
            "epoch : 16/50    time : 145s/4920s\n",
            "TRAIN    loss : 1.00389    f1 : 0.28401\n",
            "valid    loss : 0.08504    f1 : 1.00000\n",
            "epoch : 17/50    time : 144s/4768s\n",
            "TRAIN    loss : 0.98864    f1 : 0.35170\n",
            "valid    loss : 0.24900    f1 : 0.88235\n",
            "epoch : 18/50    time : 145s/4637s\n",
            "TRAIN    loss : 0.98066    f1 : 0.28181\n",
            "valid    loss : 0.23704    f1 : 0.87333\n",
            "epoch : 19/50    time : 144s/4469s\n",
            "TRAIN    loss : 1.01941    f1 : 0.31692\n",
            "valid    loss : 0.18260    f1 : 0.93684\n",
            "epoch : 20/50    time : 144s/4332s\n",
            "TRAIN    loss : 0.99487    f1 : 0.31728\n",
            "valid    loss : 0.09323    f1 : 1.00000\n",
            "epoch : 21/50    time : 145s/4200s\n",
            "TRAIN    loss : 0.98264    f1 : 0.35304\n",
            "valid    loss : 0.41723    f1 : 0.75789\n",
            "epoch : 22/50    time : 146s/4082s\n",
            "TRAIN    loss : 0.90682    f1 : 0.40021\n",
            "valid    loss : 0.07723    f1 : 0.88889\n",
            "epoch : 23/50    time : 146s/3938s\n",
            "TRAIN    loss : 0.97385    f1 : 0.27186\n",
            "valid    loss : 0.06069    f1 : 1.00000\n",
            "epoch : 24/50    time : 146s/3793s\n",
            "TRAIN    loss : 0.96163    f1 : 0.32700\n",
            "valid    loss : 0.07154    f1 : 1.00000\n",
            "epoch : 25/50    time : 146s/3642s\n",
            "TRAIN    loss : 0.97671    f1 : 0.33202\n",
            "valid    loss : 0.25406    f1 : 0.92982\n",
            "epoch : 26/50    time : 145s/3491s\n",
            "TRAIN    loss : 0.93510    f1 : 0.35318\n",
            "valid    loss : 0.15034    f1 : 0.83333\n",
            "epoch : 27/50    time : 144s/3317s\n",
            "TRAIN    loss : 0.89974    f1 : 0.41264\n",
            "valid    loss : 0.23100    f1 : 0.88889\n",
            "epoch : 28/50    time : 145s/3184s\n",
            "TRAIN    loss : 0.93085    f1 : 0.40196\n",
            "valid    loss : 0.13087    f1 : 0.92500\n",
            "epoch : 29/50    time : 145s/3042s\n",
            "TRAIN    loss : 0.84376    f1 : 0.39118\n",
            "valid    loss : 0.07568    f1 : 1.00000\n",
            "epoch : 30/50    time : 145s/2891s\n",
            "TRAIN    loss : 0.93643    f1 : 0.43077\n",
            "valid    loss : 0.27115    f1 : 0.83492\n",
            "epoch : 31/50    time : 144s/2745s\n",
            "TRAIN    loss : 0.90789    f1 : 0.31501\n",
            "valid    loss : 0.21885    f1 : 0.82456\n",
            "epoch : 32/50    time : 144s/2598s\n",
            "TRAIN    loss : 0.87312    f1 : 0.37452\n",
            "valid    loss : 0.54576    f1 : 0.68889\n",
            "epoch : 33/50    time : 145s/2462s\n",
            "TRAIN    loss : 0.88475    f1 : 0.35029\n",
            "valid    loss : 0.31510    f1 : 0.75873\n",
            "epoch : 34/50    time : 145s/2316s\n",
            "TRAIN    loss : 0.84983    f1 : 0.37014\n",
            "valid    loss : 0.05221    f1 : 1.00000\n",
            "epoch : 35/50    time : 145s/2174s\n",
            "TRAIN    loss : 0.89207    f1 : 0.40746\n",
            "valid    loss : 0.11005    f1 : 0.91837\n",
            "epoch : 36/50    time : 145s/2026s\n",
            "TRAIN    loss : 0.88168    f1 : 0.39479\n",
            "valid    loss : 0.08604    f1 : 1.00000\n",
            "epoch : 37/50    time : 145s/1886s\n",
            "TRAIN    loss : 0.93416    f1 : 0.37933\n",
            "valid    loss : 0.59576    f1 : 0.75926\n",
            "epoch : 38/50    time : 145s/1742s\n",
            "TRAIN    loss : 0.88284    f1 : 0.39928\n",
            "valid    loss : 0.07939    f1 : 0.92593\n",
            "epoch : 39/50    time : 144s/1589s\n",
            "TRAIN    loss : 0.90000    f1 : 0.38009\n",
            "valid    loss : 0.05677    f1 : 1.00000\n",
            "epoch : 40/50    time : 144s/1444s\n",
            "TRAIN    loss : 0.92045    f1 : 0.38002\n",
            "valid    loss : 0.11297    f1 : 0.93277\n",
            "epoch : 41/50    time : 145s/1304s\n",
            "TRAIN    loss : 0.82646    f1 : 0.40020\n",
            "valid    loss : 0.07700    f1 : 0.92157\n",
            "epoch : 42/50    time : 144s/1156s\n",
            "TRAIN    loss : 0.79231    f1 : 0.37003\n",
            "valid    loss : 0.05740    f1 : 1.00000\n",
            "epoch : 43/50    time : 145s/1012s\n",
            "TRAIN    loss : 0.85896    f1 : 0.40590\n",
            "valid    loss : 0.18348    f1 : 0.89744\n",
            "epoch : 44/50    time : 145s/872s\n",
            "TRAIN    loss : 0.85939    f1 : 0.34309\n",
            "valid    loss : 0.10357    f1 : 0.92381\n",
            "epoch : 45/50    time : 144s/721s\n",
            "TRAIN    loss : 0.84458    f1 : 0.39987\n",
            "valid    loss : 0.11063    f1 : 0.87500\n",
            "epoch : 46/50    time : 145s/579s\n",
            "TRAIN    loss : 0.82737    f1 : 0.41839\n",
            "valid    loss : 0.26175    f1 : 0.84127\n",
            "epoch : 47/50    time : 145s/435s\n",
            "TRAIN    loss : 0.77588    f1 : 0.44311\n",
            "valid    loss : 0.10959    f1 : 1.00000\n",
            "epoch : 48/50    time : 144s/288s\n",
            "TRAIN    loss : 0.87932    f1 : 0.39287\n",
            "valid    loss : 0.27122    f1 : 0.83459\n",
            "epoch : 49/50    time : 144s/144s\n",
            "TRAIN    loss : 0.82995    f1 : 0.39649\n",
            "valid    loss : 0.04462    f1 : 1.00000\n",
            "epoch : 50/50    time : 145s/0s\n",
            "TRAIN    loss : 0.82873    f1 : 0.35023\n",
            "valid    loss : 0.21667    f1 : 0.91111\n"
          ]
        }
      ],
      "source": [
        "def score_function(real, pred):\n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score\n",
        "\n",
        "model = Network().to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp) \n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=0.001, last_epoch=-1)\n",
        "\n",
        "\n",
        "valid_loss_list=[]\n",
        "train_loss_list=[]\n",
        "\n",
        "best=0\n",
        "for epoch in range(epochs):\n",
        "    start=time.time()\n",
        "    train_loss = 0\n",
        "    train_pred=[]\n",
        "    train_y=[]\n",
        "\n",
        "    valid_loss = 0\n",
        "    valid_pred=[]\n",
        "    valid_y=[]\n",
        "\n",
        "    model.train()\n",
        "    for batch in (train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
        "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "\n",
        "        x, targets_a, targets_b, lam = mixup_data(x, y)\n",
        "        x, targets_a, targets_b = map(Variable, (x, targets_a, targets_b))\n",
        "\n",
        "        #outputs = model(x)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(x)\n",
        "        loss = mixup_criterion(criterion, pred, targets_a, targets_b, lam)\n",
        "\n",
        "\n",
        "        #loss = criterion(pred, y)\n",
        "\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        train_loss += loss.item()/len(train_loader)\n",
        "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "        train_y += y.detach().cpu().numpy().tolist()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for i in (valid_loader):\n",
        "          images = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
        "          targets = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "\n",
        "\n",
        "\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, targets)\n",
        "\n",
        "          valid_loss += loss.item()/len(valid_loader)\n",
        "          valid_pred += outputs.argmax(1).detach().cpu().numpy().tolist()\n",
        "          valid_y += targets.detach().cpu().numpy().tolist()\n",
        "    \n",
        "    train_f1 = score_function(train_y, train_pred)\n",
        "    valid_f1 = score_function(valid_y, valid_pred)\n",
        "\n",
        "    TIME = time.time() - start\n",
        "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
        "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
        "    print(f'valid    loss : {valid_loss:.5f}    f1 : {valid_f1:.5f}')\n",
        "    lr_scheduler.step()\n",
        "    torch.save(model.state_dict(), f'{train_loss}_{train_f1}.pth')"
      ],
      "id": "QplKmNaD5h3b"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Add valid, transforms.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}